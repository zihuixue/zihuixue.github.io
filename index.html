<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta name="google-site-verification" content="ufZa3XjmGskngtrL5yh3aMO6n4-QlFMFAyP2kxPsmRw" />
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zihui Xue</title>

  <meta name="author" content="Zihui Xue">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table
    style="width:110%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Zihui (Sherry) Xue</name>
                  </p>
                  <p>
                    Hi, I am a first-year Ph.D. student at UT Austin. Previously, I obtained my bachelor's degree from Fudan University. My research interests lie in multimodal learning and graph neural networks.
                  </p>

                  <p style="text-align:center">
                    <a href="data/email.txt">Email</a> &nbsp|&nbsp
                    <a href="data/CV_Zihui Xue.pdf">CV</a> &nbsp|&nbsp
                    <a href="https://scholar.google.com/citations?hl=zh-CN&view_op=list_works&authuser=2&gmla=AJsN-F49ZRjKgLxe5u7PyuIHAq0QUMrAApYmolkUVk6TjuP8V8AEI60VMC-x2U7-6Ey6R5usFH881WFZkTNJohdyfgsW7TQMx-rBNf4fWjpPiMThSuXU8G0&user=JCV9BQ0AAAAJ">Google Scholar</a> &nbsp|&nbsp
                    <a href="https://github.com/zihuixue">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/profile2.jpg"><img style="width:90%;max-width:90%" alt="profile photo"
                      src="images/profile2.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>



          <table width="110%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>News</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="110%" align="center" border="0" cellpadding="20">
            <tbody>
              <ul>
                <li>[Sep. 2021] One paper got accepted by NeurIPS'21. ðŸŽ‰</li>
                <li>[Sep. 2021] One paper got accepted by CoRL'21. ðŸŽ‰</li>
                <li>[Jul. 2021] Two papers got accepted by ICCV'21 (one first author). ðŸŽ‰</li>
                <li>[Aug. 2020] Start working with <a href='http://people.csail.mit.edu/hangzhao/'> Prof. Hang Zhao </a> at Shanghai Qi Zhi Institue, Tsinghua University. ðŸ˜Š</li>
              </ul>
            </tbody>
          </table>



          <table
            style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:110%;vertical-align:middle">
                  <heading>Selected Projects</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:35%;vertical-align:left">
                  <div><img style="width:100%;max-width:100%" src="images/mmbetter.png"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>What Makes Multi-Modal Learning Better than Single (Provably)                   
                    </papertitle>
                  <br>
                  <br>
                  Yu Huang,
                  Chenzhuang Du,
                  <b>Zihui Xue</b>, 
                  Xuanyao Chen,
                  Hang Zhao

                  <br>
                  Conference on Neural Information Processing Systems (NeurIPS), 2021
                  <br>
                  <a href="https://openreview.net/forum?id=UlSjqPEkI1V">[paper]</a>
                  <p>
                    Can multi-modal learning provably perform better than uni-modal?
                  </p>
                </td>
              </tr>
          </table>

          <table
            style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:35%;vertical-align:left">
                  <div><img style="width:100%;max-width:100%" src="images/depth.png"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>Anytime Depth Estimation with Limited Sensing and Computation Capabilities on Mobile Devices                     
                    </papertitle>
                  <br>
                  <br>
                  Yuedong Yang,
                  <b>Zihui Xue</b>, 
                  Radu Marculescu

                  <br>
                  Conference on Robot Learning (CoRL), 2021
                  <br>
                  <a href="https://openreview.net/forum?id=I6DLxqk9J0A">[paper]</a>
                  <p>
                    Anytime Depth Estimation with energy-saving 2D LiDARs and monocular cameras.
                  </p>
                </td>
              </tr>
          </table>

          <table
            style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:35%;vertical-align:left">
                  <div><img style="width:100%;max-width:100%" src="images/MKE.png"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>Multimodal Knowledge Expansion                      
                    </papertitle>
                  <br>
                  <br>
                  <b>Zihui Xue</b>, 
                  Sucheng Ren, 
                  Zhengqi Gao, 
                  Hang Zhao

                  <br>
                  International Conference on Computer Vision (ICCV), 2021
                  <br>
                  <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Xue_Multimodal_Knowledge_Expansion_ICCV_2021_paper.pdf">[paper]</a>
                  <a href="https://tsinghua-mars-lab.github.io/MKE/">[website]</a>
                  <p>
                    A knowledge distillation-based framework to effectively utilize multimodal data without requiring labels.
                  </p>
                </td>
              </tr>
          </table>

          <table
            style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:35%;vertical-align:left">
                  <div><img style="width:100%;max-width:100%" src="images/decorr.png"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>On Feature Decorrelation in Self-Supervised Learning                      
                    </papertitle>
                  <br>
                  <br>
                  Tianyu Hua,
                  Wenxiao Wang, 
                  <b>Zihui Xue</b>, 
                  Sucheng Ren,
                  Yue Wang, 
                  Hang Zhao
                  

                  <br>
                  International Conference on Computer Vision (ICCV), 2021
                  <br>
                  (Oral, Acceptance Rate 3.0%)
                  <br>
                  <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Hua_On_Feature_Decorrelation_in_Self-Supervised_Learning_ICCV_2021_paper.pdf">[paper]</a>
                  <a href="https://tsinghua-mars-lab.github.io/decorr/">[website]</a>
                  <p>
                    Connecting dimensional collapse with strong correlations between axes and consider such connection as a strong motivation for feature decorrelation.
                  </p>
                </td>
              </tr>
          </table>

          <table
            style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:35%;vertical-align:left">
                  <div><img style="width:100%;max-width:100%" src="images/randomwalk.png"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>Sampling Graphlets of Multiplex Networks: A Restricted Random Walk Approach                
                    </papertitle>
                  <br>
                  <br>
                  Simiao Jiao, 
                  <b>Zihui Xue</b>, 
                  Xiaowei Chen,
                  Yuedong Xu
                  
                  <br>
                  ACM Transactions on the Web (TWEB)
                  <br>
                  <br>
                  <a href="https://dl.acm.org/doi/abs/10.1145/3456291">[paper]</a>
                  <p>
                    A random walk approach to estimate the graphlet concentration in multiplex networks.
                  </p>
                </td>
              </tr>
          </table>